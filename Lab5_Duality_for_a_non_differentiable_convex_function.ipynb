{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM_ErGq-k_3c"
      },
      "source": [
        "# Group Members:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**PUT NAMES OF YOUR TEAM MEMBERS HERE**"
      ],
      "metadata": {
        "id": "kabcI8Wj5cKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Name 1\n",
        "*   Name 2\n",
        "*   Name 3"
      ],
      "metadata": {
        "id": "Fnul20Qf5f0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guide"
      ],
      "metadata": {
        "id": "oJoeM0yp_REU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this practice we will study a trick to deal with some non-differentiable functions. It is based in augmenting the objective function, including new variables. In the first part we will program two basic methods and test them with toy examples in a low dimensional setting. In the second part we apply this methodology to the minimization of a non-differentiable image denoising energy.\n",
        "\n",
        "\\\\\n",
        "\n",
        "For any doubts before and after the practice, you can contact your teacher:\n",
        "\n",
        "Nneka Okolo - nnekamaureen.okolo@upf.edu\n",
        "\n",
        "Pablo Arias - pablo.arias@upf.edu\n",
        "\n",
        "Adriano Pastore - adriano.pastore@upf.edu\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Pre-requisites:** Before the practice, you should review the following topics:\n",
        "\n",
        "*   Min-max inequality, Von-Neuman min-max theorem\n",
        "*   Duality for minimizing functions with non-differentiabilities\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Deadlines**: See\n",
        "[P101](https://calendar.google.com/calendar/embed?src=c_b679939a9db8a1d8cd9f01f62d373d173f76794e4137c40e793a8d2cb11708f8%40group.calendar.google.com&ctz=Europe%2FMadrid/),\n",
        "[P102](https://calendar.google.com/calendar/embed?src=c_5a65338fe8c3ce7909e62bb6b572b1a61ff4ad3543b12f72468e1a16bca41bd0%40group.calendar.google.com&ctz=Europe%2FMadrid),\n",
        "[P201](https://calendar.google.com/calendar/embed?src=c_58aa336a0c5d0a38b13dd4a38071e7d8f9a18f4306ffeef2e48276087c339163%40group.calendar.google.com&ctz=Europe%2FMadrid),\n",
        "[P202](https://calendar.google.com/calendar/embed?src=c_dac1d492e1060f3cee35420a9c2ff0d345e89a002cc8c70fe74bf0b78bf99d37%40group.calendar.google.com&ctz=Europe%2FMadrid),\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Submission instructions**\n",
        "\n",
        "Register your group members [here](https://forms.gle/NLeYqhN6LyPnSPg78) if you haven't already.\n",
        "\n",
        "Complete the code and answer the questions below.\n",
        "\n",
        "Export the notebook with the answers using the menu option File->Download .ipynb.\n",
        "\n",
        "Rename exported notebook with the format **lastnameUid.ipynb** where lastname is the first surname of **Member 1** in the form and Uid is their UPF ID.\n",
        "\n",
        "Submit your solution [here](https://forms.gle/AdYQwDEjAta1QaRY6) by the deadline. **Only one member needs to complete this step**.\n",
        "\n",
        "You will receive an acknowledgement of receipt.\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Grading**:\n",
        "\n",
        "  The evaluation is based on results, conclusions and the commented code together.\n",
        "\n",
        "\n",
        "\n",
        "[comment]: <> (Macros:)\n",
        "$\\newcommand{\\m}{-}\n",
        "\\newcommand{\\ma}[1]{\\boldsymbol{#1}}\n",
        "\\newcommand{\\tras}[1]{#1^{\\mathrm{T}}}\n",
        "\\newcommand{\\herm}[1]{#1^{\\mathrm{H}}}\n",
        "\\newcommand{\\con}[1]{#1^{\\mathrm{*}}}\n",
        "\\newcommand{\\E}{\\mathbb{E}}\n",
        "\\newcommand{\\tech}[1]{\\overline{#1}}\n",
        "\\newcommand{\\nspace}{\\!\\!\\!\\!}\n",
        "\\newcommand{\\nmbr}[1]{\\oldstylenums{#1}}\n",
        "\\newcommand{\\eg}{\\emph{e.g}. } \\newcommand{\\Eg}{\\emph{E.g}. }\n",
        "\\newcommand{\\ie}{\\emph{i.e}. } \\newcommand{\\Ie}{\\emph{I.e}. }\n",
        "\\newcommand{\\cf}{\\emph{c.f}. } \\newcommand{\\Cf}{\\emph{C.f}. }\n",
        "\\newcommand{\\etc}{\\emph{etc}. } \\newcommand{\\vs}{\\emph{vs}. }\n",
        "\\newcommand{\\wrt}{w.r.t\\onedot } \\newcommand{\\dof}{d.o.f. }\n",
        "\\newcommand{\\etal}{\\emph{et al}. }\n",
        "\\newcommand{\\R}{\\mathbb{R}}\n",
        "\\newcommand{\\sign}{\\mathrm{sign}}\n",
        "\\newcommand{\\eps}{\\varepsilon}\n",
        "\\newcommand{\\To}{\\longrightarrow}\n",
        "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
        "\\DeclareMathOperator*{\\argmax}{arg\\,max}$"
      ],
      "metadata": {
        "id": "JCfOu0TE55xS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions for answering the questions.**\n",
        "\n",
        "Questions are indicated in blue. Some questions require answers in the form of text, some others require completing code. See the examples below. *Please do not modify the notebook outside of these cells.*"
      ],
      "metadata": {
        "id": "jzaSqp7hJYC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 42)** Based on what you know at this moment, answer these questions:\n",
        "1. What are your favorite subjects?\n",
        "2. What are your favourite hobbies?\n",
        "</font>"
      ],
      "metadata": {
        "id": "R-IHsJZ0JaKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>\n",
        "\n",
        "1. I only like one subject: \"Optimization Techniques.\"\n",
        "1. I like writing equations $e^{i\\pi} + 1 = 0$"
      ],
      "metadata": {
        "id": "xGxO_cnuJcRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 43)** This is a coding question. There is no <font color='red'>**ANSWER**</font> cell. Instead, you should complete the code cell following the question. Typically, you'll find TODOs in the code indicating the places that you are expected to complete.\n",
        "</font>"
      ],
      "metadata": {
        "id": "LjfQhH4OJeoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = None     # TODO substitute the None by a nice number to print\n",
        "print(\"The number a is {}\".format(a))"
      ],
      "metadata": {
        "id": "P1YokEN8JlSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF725-X3c1UM"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "from IPython import display\n",
        "#%matplotlib widget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Min-max and max-min"
      ],
      "metadata": {
        "id": "mPqDjX2emQTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Given a function of two variables $H:X\\times Y \\to \\mathbb R$, duality relies on the relation between these two problems:\n",
        "$$\n",
        "  \\min\\limits_{x\\in X} \\max \\limits_{y\\in Y} H(x,y) \\quad\\quad\\text{ and }\\quad\\quad \\max \\limits_{y\\in Y} \\min \\limits_{x\\in X} H(x,y).\n",
        "$$\n",
        "\n",
        "As seen in theory, the min-max inequality says that\n",
        "$$\n",
        "   \\max \\limits_{y\\in Y} \\min \\limits_{x\\in X} H(x,y) \\leq \\min\\limits_{x\\in X} \\max \\limits_{y\\in Y} H(x,y).\n",
        "$$\n",
        "\n",
        "If we define the following functions:\n",
        "$$\n",
        "f(x) = \\max_y H(x,y), \\quad\\quad g(y) = \\min_x H(x,y),\n",
        "$$\n",
        "we have that:\n",
        "$$\n",
        "   g(y) \\leq \\max \\limits_{y\\in Y} \\underbrace{\\min \\limits_{x\\in X} H(x,y)}_{g(y)} \\leq \\min\\limits_{x\\in X} \\underbrace{\\max \\limits_{y\\in Y} H(x,y)}_{f(x)} \\leq f(x).\n",
        "$$\n",
        "The dual gap is given by the following difference\n",
        "$$\n",
        "\\text{DG}(x,y) = f(x) - g(y)\n",
        "$$\n",
        "and it is always non-negative. The smallest possible dual gap is the given by\n",
        "$$\n",
        "\\text{DG}^* = \\min_x f(x) - \\max_y g(y).\n",
        "$$\n",
        "In some cases, the optimal dual gap is zero, and we have seen in theory that this is related with the existence of a saddle point $(x^*,y^*)$: a point which is a minimizer of $H$ with respecto $x$ and maximizer with respect to $y$:\n",
        "$$ H(x^*,y) \\leq H(x^*,y^*) \\leq H(x,y^*).$$\n",
        "\n",
        "\n",
        "In the first part of the lab we will visualize some functions $H$ of two variables defined over $[-4,4]\\times [-4,4]$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uk9EOAIsW9Ma"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqBr6pBAc1UP"
      },
      "source": [
        "<font color='blue'>**(QUESTION 1)** Complete the code of the function `compute_dual_gap()` below.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dual_gap(x, y, H):\n",
        "  \"\"\"\n",
        "  Computes the optimal dual gap for a discretized function of 2 variables.\n",
        "  The input is a 2D np.array H with the values of a function over a rectangular\n",
        "  2D grid.\n",
        "  \"\"\"\n",
        "\n",
        "  max_y_H = None# TODO hint use np.max, but identify which axis corresponds to y\n",
        "  min_x_H = None# TODO                                                  and to x\n",
        "  optimal_dual_gap = # TODO\n",
        "\n",
        "  # plot\n",
        "  plt.plot(x, max_y_H, label='max_y H(x, y)')\n",
        "  plt.plot(y, min_x_H, label='min_x H(x, y)')\n",
        "  plt.grid()\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  return optimal_dual_gap"
      ],
      "metadata": {
        "id": "l2asZIq_9zXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WtbcwPRHja3"
      },
      "source": [
        "<font color='blue'>**(QUESTION 1.1)** Run the cells below, that will display plots of some functions of two variables.\n",
        "- <font color='blue'>\n",
        " Determine visually which of the functions displayed presents a saddle point and which do not. In case there is a saddle-point provide its approximate coordinates.\n",
        "- Which is the necessary condition seen in theory for the existence of a saddle point? Are these examples compatible with that necessary condition?\n",
        "\n",
        "Insert your answers in the <font color='red'>**ANSWER**</font> box underneath.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqszm9xKYtW2"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def surf_and_contour(x, y, H, label=None, fig_size=None, levels=60):\n",
        "\n",
        "  fig = make_subplots(rows=1, cols=2, specs=[[{'type': 'surface'}, {}]])\n",
        "\n",
        "  fig.add_trace(go.Surface(x=x,y=y,z=H), row=1, col=1)\n",
        "  fig.layout.scene.camera.projection.type = \"orthographic\"\n",
        "\n",
        "  fig.update_layout(title=label, autosize=False,\n",
        "                    width=1000, height=500,\n",
        "                    margin=dict(l=65, r=50, b=65, t=90))\n",
        "\n",
        "  fig.add_trace(go.Contour(x=x,y=y,z=H,\n",
        "                           contours_coloring='lines',\n",
        "                           ncontours=40,\n",
        "                           line_width=1), row=1, col=2)\n",
        "\n",
        "  fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "\n",
        "# Define the grid\n",
        "start = -5\n",
        "stop = 5\n",
        "step = .05\n",
        "x = np.arange(start = start, stop = stop + step, step = step)\n",
        "y = np.arange(start = start, stop = stop + step, step = step)\n",
        "\n",
        "# Create the mesh grid\n",
        "xx, yy = np.meshgrid(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "onTGof87l2bA"
      },
      "source": [
        "# FIRST FUNCTION\n",
        "H1 = np.power(xx, 2) - np.power(yy, 2)\n",
        "surf_and_contour(x, y, H1, label='H1(x,y) = x^2 - y^2')\n",
        "\n",
        "optimal_dual_gap = compute_dual_gap(x, y, H1)\n",
        "print('Optimal dual gap in [-4,4]x[-4,4] is %f' % optimal_dual_gap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FatPgaJPqkHE"
      },
      "source": [
        "# SECOND FUNCTION\n",
        "H2 = 2 * xx + yy\n",
        "surf_and_contour(x, y, H2, label='f2(x,y) = 2x + y')\n",
        "\n",
        "optimal_dual_gap = compute_dual_gap(x, y, H2)\n",
        "print('Optimal dual gap in [-4,4]x[-4,4] is %f' % optimal_dual_gap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Wdtdt6tuq3Ts"
      },
      "source": [
        "# THIRD FUNCTION\n",
        "H3 = np.power(xx, 2) + np.power(yy, 2)\n",
        "surf_and_contour(x, y, H3, label='H3(x,y) = x^2 + y^2')\n",
        "\n",
        "optimal_dual_gap = compute_dual_gap(x, y, H3)\n",
        "print('Optimal dual gap in [-4,4]x[-4,4] is %f' % optimal_dual_gap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uZNa8nNtq4bM"
      },
      "source": [
        "# FOURTH FUNCTION\n",
        "H4 = np.cos((3 / 5) * (xx + yy)) + 0.25 * xx\n",
        "surf_and_contour(x, y, H4, label='f4(x,y) = cos(3/5(x + y)+x/4)')\n",
        "\n",
        "optimal_dual_gap = compute_dual_gap(x, y, H4)\n",
        "print('Optimal dual gap in [-4,4]x[-4,4] is %f' % optimal_dual_gap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bNMhYeWfq5Ej"
      },
      "source": [
        "# FIFTH FUNCTION\n",
        "H5 = xx*yy\n",
        "surf_and_contour(x, y, H5, label='f5(x,y) = xy')\n",
        "\n",
        "optimal_dual_gap = compute_dual_gap(x, y, H5)\n",
        "print('Optimal dual gap in [-4,4]x[-4,4] is %f' % optimal_dual_gap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>\n",
        "\n"
      ],
      "metadata": {
        "id": "R3MiBkQS2vih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The primal-dual and the dual method"
      ],
      "metadata": {
        "id": "-xcwTAy8PUAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now exploit min-max duality theory to minimize functions $ f:\\mathbb{R}^n\\to\\mathbb{R}$ of the form:\n",
        "$$\n",
        "f(x)=\\| Ax \\|_{\\mathbb R^m} + \\frac{1}{2\\lambda} \\| x-b\\|_{\\mathbb R^n}^2\n",
        "$$\n",
        "where $A$ is a $m\\times n$ matrix and $b\\in \\mathbb{R}^n$. This function has a particularity: since the first norm is not squared, it is not differentiable when $Ax=0$. This creates a difficulty: all the minimization algorithms we've seen so far use $\\nabla f$ in a way or another. Here we cannot use it, since $\\nabla f$ is not defined when $Ax=0$. In this assignment we will see a trick to deal with this issue.\n",
        "\n",
        "\n",
        "**Removing the non-differentiability with an auxiliary variable**\n",
        "\n",
        "We can remove the non-differentiability by formulating an equivalent problem with an additional variable. It all resides in the following observation:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\| x\\|_{\\mathbb R^n} = \\max\\limits_{\\| y\\|_{\\mathbb R^n}\\leq 1} \\langle x,y\\rangle_{\\mathbb R^n}. \\qquad (1)\n",
        "\\end{equation}\n",
        "\n",
        "Applying this to our problem, we have that\n",
        "\n",
        "$$\n",
        "f(x) = \\max\\limits_{y\\in C} H(x,y) \\; \\text{ where } H(x,y)= \\langle Ax,y\\rangle_{\\mathbb R ^m} + \\frac{1}{2 \\lambda} \\|x-b\\|^2_{\\mathbb R^n},\n",
        "$$\n",
        "\n",
        "where we have defined the feasible set for $y$ as $ C = \\{y \\in \\mathbb R^m : \\|y\\|_{\\mathbb R^m} \\leq 1 \\}$, the set of vectors with norm less or equal to one. Since we want to minimize $f$, we are interested in finding\n",
        "\n",
        "$$\n",
        "\\min\\limits_x \\max \\limits_{y\\in C} H(x,y).\n",
        "$$\n",
        "\n",
        "So far we haven't done much. We changed our original non-differentiable problem by another one, a min-max problem.\n",
        "\n",
        "The following observation will help us. $H$ has very particular properties: for any fixed $x$, $H(x,\\cdot)$ is a concave function. On the other hand $H(\\cdot,y)$ is convex, for any fixed $y$. This implies that we can exchange the min with the max. The result is a max-min problem:\n",
        "\n",
        "$$\n",
        "  \\min\\limits_x \\max \\limits_{y\\in C} H(x,y) = H(x^*,y^*) = \\max \\limits_{y\\in C} \\min \\limits_x H(x,y). \\quad (2)\n",
        "$$\n",
        "\n",
        "Here $(x^*,y^*)$ is the solution of the min-max and max-min problems. It can be shown that $(x ^*,y^*)$ is a saddle point of $H$."
      ],
      "metadata": {
        "id": "L91P6CdiKBu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Eq. (2) provides an alternative problem (the max-min) which is equivalent to the original min-max problem. We are going to see two ways of solving the max-min problem:\n",
        "\n",
        "1. **The dual method**: Eliminating $x$ by solving first the min part. Then, solving the max problem of a function that only depends on $y$. This function is called the dual function, and $y$ is called the dual variable. Correspondingly $f$ is called the primal function and $x$ is the primal variable.\n",
        "2. **The primal-dual method**: Solving for $x$ and $y$ simultaneously, finding a saddle-point of $H$. This approach is called primal-dual.\n",
        "\n",
        "Let us start by explaining the latter.\n",
        "\n",
        "## The primal-dual problem\n",
        "\n",
        "A saddle point is a maximum of $H$ with respect to $y$ and a minimum with respect to $x$. A simple algorithm for computing a saddle-point is then to update the dual variable with a gradient ascent on $y$ and the primal with a gradient descent on $x$. Note that since the maximization on $y$ is constrained, we will use a projected gradient ascent."
      ],
      "metadata": {
        "id": "U9AyDaJ53rav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 2)** Show that the partial gradients of $H$, $\\nabla_xH$ and $\\nabla_yH$ with respect to $x$ and $y$ are given by\n",
        "$$\n",
        "\\nabla_x H(x,y) = A^Ty + \\frac{1}{\\lambda}(x-b)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\nabla_y H(x,y) = Ax\n",
        "$$\n",
        "</font>"
      ],
      "metadata": {
        "id": "aV9fsV7Y0ZGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>\n"
      ],
      "metadata": {
        "id": "SnQMGlsu0_bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This yields the following update equations:\n",
        "$$\n",
        "x^{k+1}=x^k - \\theta \\left(A^Ty^k + \\frac{1}{\\lambda}(x^k-b)\\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "y^{k+1} = P_C(y^k + \\delta A x^{k+1})\n",
        "$$\n",
        "\n",
        "Here $\\delta, \\theta$ are time steps that have to be specified, and $P_C$ is a projector over $C$. Given any vector $\\nu \\in \\mathbb R^m$, we have that\n",
        "\n",
        "$$\n",
        "P_C(\\nu)=\\frac{\\nu}{\\max\\big\\{1, \\|\\nu\\|_{\\mathbb R^m}\\big\\}}.\n",
        "$$"
      ],
      "metadata": {
        "id": "AlzZNuhk06Wk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2kVUjhLc1UR"
      },
      "source": [
        "<font color='blue'>**(QUESTION 3)** Complete the function `toy_primal_dual` defined below. Follow the comments provided in the code.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybNa5Ma2c1UR"
      },
      "source": [
        "def toy_primal_dual(A, b, lambda_, x, pd_prms, fig_data = None):\n",
        "    \"\"\"\n",
        "    toy_primal_dual - minimizes a non-differentiable function f:R^n--> R of the\n",
        "    form\n",
        "\n",
        "       f(x) = ||Ax|| + 1/(2*lambda)*||x-b||^2.\n",
        "\n",
        "    using a form of duality to remove the non-differentiability. It transforms\n",
        "    the problem into a max-min problem, solved numerically with a gradient\n",
        "    descent and gradient ascent.\n",
        "\n",
        "    [x,y] = toy_primal_dual (A, b, lambda, x, pd_prms)\n",
        "\n",
        "    :param A       : mxn matrix (n is the dimension of x)\n",
        "    :param b       : nx1 vector\n",
        "    :param lambda  : weight between two terms\n",
        "    :param x       : nx1 initial condition for primal variable\n",
        "    :param pd_prms : a structure with the dual maximization parameters. Needs to have\n",
        "                     the following fields:\n",
        "\n",
        "                        :param delta     : dual gradient ascent step size\n",
        "                        :param theta     : primal gradient descent step size\n",
        "                        :param max_iters : maximum number of iterations\n",
        "                        :param tolerance : tolerance for the stopping condition (it stop when\n",
        "                                           the norm of the gradient is below the tolerance)\n",
        "\n",
        "    :return x     : primal value found (nx1)\n",
        "    :return y     : dual   value found (mx1)\n",
        "    :return fps   : evolution of the primal function (total_iters x 1 vector)\n",
        "    :return fds   : evolution of the dual function (total_iters x 1 vector)\n",
        "    \"\"\"\n",
        "    # Get all the params\n",
        "    tolerance = pd_prms.get(\"tolerance\")\n",
        "    max_iters = pd_prms.get(\"max_iters\")\n",
        "    delta     = pd_prms.get(\"delta\")\n",
        "    theta     = pd_prms.get(\"theta\")\n",
        "\n",
        "    # initialize dual to 0\n",
        "    y = 0 * x\n",
        "\n",
        "    # vectors with function values\n",
        "    fps = []\n",
        "    fds = []\n",
        "\n",
        "    # begin projected gradient ascent\n",
        "    it = 0\n",
        "    dual_gap = np.inf\n",
        "    while (dual_gap > tolerance) and (it < max_iters):\n",
        "        # Increment the iteration\n",
        "        it = it + 1\n",
        "\n",
        "        # Save the current value, just for displaying\n",
        "        x_old = x\n",
        "        y_old = y\n",
        "\n",
        "        # TODO: update x by gradient descent with step theta\n",
        "        x = None\n",
        "        # TODO: update y by gradient ascent with step delta\n",
        "        y = None\n",
        "        # TODO: project y over constraint set\n",
        "        y = None\n",
        "\n",
        "        # compute primal energy\n",
        "        P_data = (1 / 2 / lambda_) * np.power(x - b, 2).sum()\n",
        "        P = np.linalg.norm(np.dot(A, x)) + P_data\n",
        "\n",
        "        # compute dual energy\n",
        "        Aty = np.dot(A.T, y)\n",
        "        D = np.dot(b.T, Aty) - lambda_ / 2 * np.power(Aty, 2).sum()\n",
        "\n",
        "        # compute primal dual energy\n",
        "        PD = np.dot(np.dot(A, x).T, y) + P_data\n",
        "\n",
        "        # TODO: update dual gap\n",
        "        dual_gap = None\n",
        "\n",
        "        # Update the arrays\n",
        "        fps.append(P)\n",
        "        fds.append(D)\n",
        "\n",
        "        # Update the plot\n",
        "        if fig_data is not None:\n",
        "            # ----\n",
        "            if x.shape[0] == 2 and x.shape[1] == 1:\n",
        "                fig_data[1].plot([x_old[0, 0], x[0, 0]],\n",
        "                                 [x_old[1, 0], x[1, 0]], \"-k\")\n",
        "                fig_data[2].plot([y_old[0, 0], y[0, 0]],\n",
        "                                 [y_old[1, 0], y[1, 0]], \"-k\")\n",
        "                fig_data[3].scatter(x[0, 0], x[1, 0], P, marker = \"o\", color = \"k\")\n",
        "                fig_data[4].scatter(y[0, 0], y[1, 0], D, marker = \"o\", color = \"k\")\n",
        "\n",
        "            elif x.shape[0] == 1 and x.shape[1] == 1:\n",
        "                fig_data[1].plot(x, P, marker = '.', color = \"k\")\n",
        "                fig_data[2].plot(y, D, marker = '.', color = \"k\")\n",
        "                fig_data[3].plot([x_old[0, 0], x[0, 0]],\n",
        "                                 [y_old[0, 0], y[0, 0]], \"-k\")\n",
        "                fig_data[4].scatter(x, y, PD, marker = \"o\", color = \"k\")\n",
        "\n",
        "            else:\n",
        "                pass\n",
        "            # ----\n",
        "            display.clear_output(wait=True)\n",
        "            display.display(fig_data[0])\n",
        "\n",
        "        # Print the current values\n",
        "        print('[It. {0} of {1}] f( x(k) ) - g( y(k) )| = {2}'.format(it, max_iters,dual_gap))\n",
        "\n",
        "    return x, y, fps, fds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zBPvpgFc1UT"
      },
      "source": [
        "## The dual problem: constrained maximization\n",
        "\n",
        "The dual problem is obtained from the max-min problem by solving first the min part:\n",
        "\n",
        "$$\n",
        " \\min \\limits_x H(x,y) = \\min\\limits_x \\langle Ax,y \\rangle _{\\mathbb R^m} + \\frac{1}{2\\lambda} \\|x-b\\|^2_{\\mathbb R^n}.\n",
        "$$\n",
        "\n",
        "This is an unconstrained minimization problem with a differentiable objective function. It is in fact, a quadratic function of $x$, and for each $y$ there is a unique minimizer $x^*(y)$ (this minimizer depends on $y$)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 4)** Show that $x^*(y)$ (the minimizer of $H(x,y)$ with respect to $x$ by keeping fixed $y$) is given by $x^*(y) = b-\\lambda A^Ty.$\n",
        "</font>"
      ],
      "metadata": {
        "id": "Ztwn9l9q5g48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>\n",
        "\n"
      ],
      "metadata": {
        "id": "YhGmaHwe6J9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Substituting $x^*(y)$ one obtains the dual function:\n",
        "\n",
        "$$\n",
        "g(y) = \\min \\limits_x H(x,y) = H(x^*(y),y) = \\langle Ab,y \\rangle_{\\mathbb R^m} - \\frac{\\lambda}{2} \\| A^Ty \\|^2_{\\mathbb R^m}.\n",
        "$$\n",
        "\n",
        "Once the min part is solved, we only have to solve the max part. This is the dual problem:\n",
        "\n",
        "$$\n",
        "\\max\\limits_{y\\in C} g(y) = \\max_{y\\in C} \\langle Ab,y \\rangle_ {\\R^m} - \\frac{\\lambda}{2} \\|A^Ty\\|^2_{\\mathbb R^m}\n",
        "$$\n",
        "\n",
        "Observe that this is a quadratic problem with constraints, where we have eliminated the primal variable. We can solve it with a projected gradient ascent."
      ],
      "metadata": {
        "id": "y7RspS_T5eP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 5)** Show that $\\nabla g(y)$ is given by $\\nabla g(y) = Ab - \\lambda AA^Ty$.\n",
        "</font>"
      ],
      "metadata": {
        "id": "02RK-7-k6VIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>\n",
        "\n"
      ],
      "metadata": {
        "id": "aivZRd4v6g2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we can express $\\nabla g(y)$ as $\\nabla g(y) = A(b -\\lambda A^Ty) = Ax^*(y)$. Putting all of this together, we get the following maximization scheme. We start from $y^0 \\in C $ (for example $y = 0$) and we use a time step $\\delta$. Then, iterate:\n",
        "\n",
        "$$\n",
        "y^{k+1} = P_C(y^k + \\delta Ax^*(y^k)).\n",
        "$$\n",
        "\n",
        "Once we compute the dual optimum, say $y^*$, we can recover the primal optimum by substituting $y^*$ into $x^* = x^*(y^*)$.\n",
        "\n",
        "## The dual gap and the stopping condition\n",
        "\n",
        "\n",
        "As a criterion for the stopping condition for our iterative algorithms we will use the dual gap:\n",
        "\n",
        "$$\\text{DG}(x,y) = f(x) - g(y).$$\n",
        "\n",
        "From the properties of min-max problems of the first part we know that\n",
        "\n",
        "$$f(x) \\geq f(x^*) = H(x^*,y^*) = g(y^*) \\geq g(y).$$\n",
        "\n",
        "This implies that $f(x)- g(y) \\geq f(x)- f(x^*) \\geq 0$. This means that the dual gap bounds the error between the current estimate $f(x)$ and the minimum $f(x^*)$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I1tIOW-B6Sit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A problem with one primal and one dual variable"
      ],
      "metadata": {
        "id": "aO7Lac08m7if"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 6)** Complete the function `toy_dual` defined below. Follow the comments provided in the code.\n",
        "</font>"
      ],
      "metadata": {
        "id": "0LyvQmC26zGu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTDDLsh4c1UT"
      },
      "source": [
        "def toy_dual(A, b, lambda_, d_prms, fig_data = None):\n",
        "    \"\"\"\n",
        "    toy_dual - minimizes a non-differentiable function f:R^n --> R of the form\n",
        "\n",
        "       f(x) = ||Ax|| + 1/2/lambda*|| x - b ||^2.\n",
        "\n",
        "    using a form of duality to remove the non-differentiability. It transforms\n",
        "    the problem into a max-min problem, eliminates the primal by solving the min\n",
        "    analytically, and solves the max numerically with a gradient ascent.\n",
        "\n",
        "    [x,y] = toy_dual (A, b, lambda, d_prms)\n",
        "\n",
        "    :param A      : mxn matrix (n is the dimension of x)\n",
        "    :param b      : nx1 vector\n",
        "    :param lambda : weight between two terms\n",
        "    :param d_prms : a structure with the dual maximization parameters. Needs to have\n",
        "                    the following fields:\n",
        "                   :param delta     : gradient ascent step size\n",
        "                   :param max_iters : maximum number of iterations\n",
        "                   :param tolerance : tolerance for the stopping condition (it stop when\n",
        "                                      the norm of the gradient is below the tolerance)\n",
        "\n",
        "    :return x     : primal value found (nx1)\n",
        "    :return y     : dual   value found (mx1)\n",
        "    :return fps   : evolution of the primal function (total_iters x 1 vector)\n",
        "    :return fds   : evolution of the dual function (total_iters x 1 vector)\n",
        "    \"\"\"\n",
        "    # Get all the params\n",
        "    tolerance = d_prms.get(\"tolerance\")\n",
        "    max_iters = d_prms.get(\"max_iters\")\n",
        "    delta     = d_prms.get(\"delta\")\n",
        "\n",
        "    # Initialization\n",
        "    y = np.zeros((len(A), 1))\n",
        "\n",
        "    # TODO: Initialize x\n",
        "    x = None\n",
        "\n",
        "    # vectors with function values\n",
        "    fps = []\n",
        "    fds = []\n",
        "\n",
        "    # begin projected gradient ascent\n",
        "    it = 0\n",
        "    dual_gap = np.inf\n",
        "    while (dual_gap > tolerance) and (it < max_iters):\n",
        "        # Increment the iteration\n",
        "        it = it + 1\n",
        "\n",
        "        # Save the current value, just for displaying\n",
        "        y_old = y\n",
        "\n",
        "        # TODO: update y by gradient ascent with step delta\n",
        "        y = None\n",
        "\n",
        "        # project y over constraint set\n",
        "        y = None\n",
        "\n",
        "        # Save the current value, just for displaying\n",
        "        x_old = x\n",
        "\n",
        "        # TODO: compute primal variable as x^*(xi)\n",
        "        x = None\n",
        "\n",
        "        # compute primal energy\n",
        "        P_data = (1 / 2 / lambda_) * np.power(x - b, 2).sum()\n",
        "        P = np.linalg.norm(np.dot(A, x)) + P_data\n",
        "\n",
        "        # compute dual energy\n",
        "        Aty = np.dot(A.T, y)\n",
        "        D = np.dot(b.T, Aty) - lambda_ / 2 * np.power(Aty, 2).sum()\n",
        "\n",
        "        # compute primal dual energy - only for plotting\n",
        "        PD = np.dot(np.dot(A, x).T, y) + P_data\n",
        "\n",
        "        # TODO: update dual gap\n",
        "        dual_gap = None\n",
        "\n",
        "        # Update the arrays\n",
        "        fps.append(P)\n",
        "        fds.append(D)\n",
        "\n",
        "        # Update the plot\n",
        "        if fig_data is not None:\n",
        "            # ----\n",
        "            if x.shape[0] == 2 and x.shape[1] == 1:\n",
        "                fig_data[1].plot([x_old[0, 0], x[0, 0]],\n",
        "                                 [x_old[1, 0], x[1, 0]], \"-k\")\n",
        "                fig_data[2].plot([y_old[0, 0], y[0, 0]],\n",
        "                                 [y_old[1, 0], y[1, 0]], \"-k\")\n",
        "                fig_data[3].scatter(x[0, 0], x[1, 0], P, marker = \"o\", color = \"k\")\n",
        "                fig_data[4].scatter(y[0, 0], y[1, 0], D, marker = \"o\", color = \"k\")\n",
        "\n",
        "            elif x.shape[0] == 1 and x.shape[1] == 1:\n",
        "                fig_data[1].plot(x, P, marker = '.', color = \"k\")\n",
        "                fig_data[2].plot(y, D, marker = '.', color = \"k\")\n",
        "                fig_data[3].plot([x_old[0, 0], x[0, 0]],\n",
        "                                 [y_old[0, 0], y[0, 0]], \"-k\")\n",
        "                fig_data[4].scatter(x, y, PD, marker = \"o\", color = \"k\")\n",
        "\n",
        "            else:\n",
        "                pass\n",
        "            # ----\n",
        "            display.clear_output(wait=True)\n",
        "            display.display(fig_data)\n",
        "\n",
        "        # Print the current values\n",
        "        print('[It. {0} of {1}] f( x(k) ) - g( y(k) ) = {2}'.format(it, max_iters,dual_gap))\n",
        "\n",
        "    return x, y, fps, fds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPzZMrEMc1UU"
      },
      "source": [
        "<font color='blue'>**(QUESTION 7)** Use the cells below to run the primal dual and dual method for a toy problem with a single variable.\n",
        "- <font color='blue'>Explain the what the displayed plots show\n",
        "- Which algorithm exhibits faster convergence\n",
        "- Run both algorithms for lambda = 3 and lambda = 10. How is the trajectory of the primal-dual variable $(x_y, y_k)$ for the *primal-dual algorithm* (specially noticeable for lambda = 10)?\n",
        "- For the *dual* algorithm, how is the trajectory of the *primal-dual variable* $x_k, y_k$? Why is that?\n",
        "\n",
        "Give your answer in the <font color='red'>**ANSWER**</font> boxes underneath.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Shl0VDc1UU"
      },
      "source": [
        "def plot_toy_problem_R1(A, b, lambda_):\n",
        "    \"\"\"\n",
        "    Function that prepares 4 plots that will be used to display the evolution\n",
        "    of the iterations of the primal dual and dual methods.\n",
        "\n",
        "    The four plots are:\n",
        "    - the primal function f\n",
        "    - the dual function g\n",
        "    - countour and surf plots of the primal-dual function H\n",
        "\n",
        "    The function returns the handles to the figure and the four axes.\n",
        "    This handles need to be passed as input to the dual and primal dual solvers.\n",
        "    \"\"\"\n",
        "\n",
        "    # vector x to plot primal function\n",
        "    x = np.matrix(np.arange(start = -5, stop = 5.01, step = .01))\n",
        "    pmg_sz = len(x)\n",
        "\n",
        "    # vector y to plot dual function\n",
        "    y = np.matrix(np.arange(start = -1.1, stop = 1.1, step = .01))\n",
        "    dmg_sz = len(y)\n",
        "\n",
        "    # compute primal function on x\n",
        "    Ax = A * x\n",
        "    f1 = np.sqrt(np.power(Ax, 2))\n",
        "    f2 = np.power(x - np.tile(b, [1, pmg_sz]), 2)\n",
        "    f  = f1 + (1 / (2 * lambda_)) * f2\n",
        "\n",
        "    # compute dual function on y\n",
        "    Aty = A.T * y\n",
        "    g = np.dot(b.T, Aty) - lambda_ / 2 * np.power(Aty, 2)\n",
        "    g = np.where(np.power(y, 2) > 1, np.nan, g)\n",
        "\n",
        "    # compute primal-dual function on a primal-dual grid\n",
        "    X, Y = np.meshgrid(x,y) # this is a primal-dual grid\n",
        "    pdmg_sz = len(X)\n",
        "\n",
        "    H = np.tile(f2, [dmg_sz, 1]) / (2 * lambda_) + y.T * Ax\n",
        "    H = np.where(np.power(Y, 2) > 1, np.nan, H)\n",
        "\n",
        "    # plots\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows = 2, ncols = 2, figsize = (14, 8))\n",
        "    ax4 = fig.add_subplot(2, 2, 4, projection='3d')\n",
        "    ax1.plot(np.array(x)[0], np.array(f)[0])\n",
        "    ax2.plot(np.array(y)[0], np.array(g)[0])\n",
        "\n",
        "    ax3.contour(X, Y, H,\n",
        "                corner_mask = False, levels = 150,\n",
        "                linewidths=(1,), cmap = cm.coolwarm)\n",
        "    ax3.grid()\n",
        "\n",
        "    ax4.plot_surface(X, Y, H, cmap=cm.coolwarm,\n",
        "                     linewidth=0, antialiased=False,\n",
        "                     vmax=1)\n",
        "\n",
        "    ax1.set_title(\"Primal\")\n",
        "    ax2.set_title(\"Dual\")\n",
        "    ax3.set_title(\"Primal Dual\")\n",
        "    ax4.set_title(\"Primal Dual\")\n",
        "\n",
        "    return fig, ax1, ax2, ax3, ax4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4ge6SgzIlJl"
      },
      "source": [
        "# parameters of primal function\n",
        "A = np.identity(n = 1)\n",
        "b = np.matrix([-6])\n",
        "lambda_ = 3  # TRY also lambda_ = 10\n",
        "\n",
        "fig_data_r1 = plot_toy_problem_R1(A, b, lambda_)\n",
        "\n",
        "# run primal dual\n",
        "x0 = np.matrix([3])\n",
        "pd_prms = {\"delta\": 0.05,\n",
        "           \"theta\": 0.5,\n",
        "           \"max_iters\": 1000,\n",
        "           \"tolerance\": 1e-8}\n",
        "\n",
        "x, y, fps, fds = toy_primal_dual(A, b, lambda_, x0, pd_prms, fig_data_r1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-U2gyzic1UV"
      },
      "source": [
        "# parameters of primal function\n",
        "A = np.identity(n = 1)\n",
        "b = np.matrix([-6])\n",
        "lambda_ = 3 # TRY also lambda_ = 10\n",
        "\n",
        "fig_data_r1 = plot_toy_problem_R1(A, b, lambda_)\n",
        "\n",
        "d_prms = {\"delta\": 2e-2,\n",
        "          \"max_iters\": 1000,\n",
        "          \"tolerance\": 1e-8}\n",
        "x, y, fps, fds = toy_dual(A, b, lambda_, d_prms, fig_data_r1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>\n",
        "\n"
      ],
      "metadata": {
        "id": "ylpYmPon9B1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A problem with two primal and two dual variables"
      ],
      "metadata": {
        "id": "_3S9Ph3InJGj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U22SxLDqY0_b"
      },
      "source": [
        "<font color='blue'>**(QUESTION 8)** Use the cells below to run the primal dual and dual method for a toy problem with two primal and two dual variables.\n",
        "- <font color='blue'>Explain the what the displayed plots show\n",
        "- For the primal dual algorithm, do the trajectories of the primal $x_k$ variable and dual $y_k$ resemble a gradient descent/ascent? What about for the dual algorithm? Justify your answer.\n",
        "- Run both algorithms for lambda = 4 and lambda = 12. When the solution of the dual is on the interior of the unit disc, where is the solution of the primal problem?\n",
        "\n",
        "Give your answer in the <font color='red'>**ANSWER**</font> boxes underneath.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MWqsoU4OJL_"
      },
      "source": [
        "def plot_toy_problem_R2(A, b, lambda_):\n",
        "    \"\"\"\n",
        "    Function that prepares 4 plots that will be used to display the evolution\n",
        "    of the iterations of the primal dual and dual methods.\n",
        "\n",
        "    In this case x and y are two dimensional variables. Therefore, H(x,y) is a\n",
        "    function of 4 variables and we cannot plot it. We only plot the primal and\n",
        "    the dual functions. For each of them, we will plot a surface and a contour\n",
        "    plot.\n",
        "\n",
        "    The function returns the handles to the figure and the four axes.\n",
        "    This handles need to be passed as input to the dual and primal dual solvers.\n",
        "    \"\"\"\n",
        "    # primal mesh to draw primal function\n",
        "    xx1 = np.matrix(np.arange(start = -15, stop = 10.1, step = .1))\n",
        "    xx2 = np.matrix(np.arange(start = -10, stop = 15.1, step = .1))\n",
        "    [x1, x2] = np.meshgrid(xx1, xx2)\n",
        "    x = np.vstack((x1.T.flatten(), x2.T.flatten()))\n",
        "    pmg_sz = x1.shape\n",
        "\n",
        "    # dual mesh to draw dual function\n",
        "    xy1 = np.matrix(np.arange(start = -1.1, stop = 1.1, step = .01))\n",
        "    xy2 = np.matrix(np.arange(start = -1.1, stop = 1.1, step = .01))\n",
        "    [y1, y2] = np.meshgrid(xy1, xy2)\n",
        "    y = np.vstack((y1.T.flatten(), y2.T.flatten()))\n",
        "    dmg_sz = y1.shape\n",
        "\n",
        "\n",
        "    # compute primal function on primal grid\n",
        "    Ax = np.dot(A, x)\n",
        "    f1 = np.sqrt(np.power(Ax, 2).sum(axis = 0))\n",
        "    f2 = np.power(x - np.tile(b, [1, np.prod(pmg_sz)]), 2).sum(axis = 0)\n",
        "    f  = np.reshape(f1, pmg_sz).T + (1 / (2 * lambda_)) * np.reshape(f2, pmg_sz).T\n",
        "\n",
        "    # compute dual function on dual grid\n",
        "    Aty = np.dot(A.T, y)\n",
        "    g = np.reshape(np.dot(b.T, Aty) - lambda_ / 2 * np.power(Aty,  2).sum(axis = 0), dmg_sz).T\n",
        "    g = np.where((np.power(y, 2).sum(axis = 0) > 1).reshape(dmg_sz), np.nan, g)\n",
        "\n",
        "    # ------- #\n",
        "    # PLOT\n",
        "    # ------- #\n",
        "    # Make the plots\n",
        "\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows = 2, ncols = 2, figsize = (14, 8))\n",
        "    ax3 = fig.add_subplot(2, 2, 3, projection='3d')\n",
        "    ax4 = fig.add_subplot(2, 2, 4, projection='3d')\n",
        "\n",
        "    ax1.contour(x1, x2, f,\n",
        "            corner_mask = False, levels = 150,\n",
        "            linewidths=(1,), cmap = cm.coolwarm)\n",
        "    ax1.grid()\n",
        "    ax1.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    ax2.contour(y1, y2, g,\n",
        "                corner_mask = False, levels = 150,\n",
        "                linewidths=(1,), cmap = cm.coolwarm)\n",
        "    ax2.grid()\n",
        "    ax2.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    ax3.plot_surface(x1, x2, f, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
        "    ax4.plot_surface(y1, y2, g, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
        "\n",
        "    ax1.set_title(\"Primal function\")\n",
        "    ax2.set_title(\"Dual function\")\n",
        "    ax3.set_title(\"Primal function\")\n",
        "    ax4.set_title(\"Dual function\")\n",
        "\n",
        "    return fig, ax1, ax2, ax3, ax4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp11e-dLOQPs"
      },
      "source": [
        "# parameters of primal function\n",
        "A = np.matrix([[1, -.5], [-.5, 1]])\n",
        "b = np.matrix([[-10], [3]])\n",
        "lambda_ = 4 # TRY also lambda = 12\n",
        "\n",
        "fig_data_r2 = plot_toy_problem_R2(A, b, lambda_)\n",
        "\n",
        "# primal dual ----------------------------------------------\n",
        "pd_prms = {\"tolerance\": 1e-4,\n",
        "           \"delta\": 1e-1,\n",
        "           \"theta\": 1e-0,\n",
        "           \"max_iters\": 1000}\n",
        "x_star, y_star, fps, fds = toy_primal_dual(A, b, lambda_, np.matrix([[5], [-5]]), pd_prms, fig_data_r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S91TBB_PH9Y"
      },
      "source": [
        "# parameters of primal function\n",
        "A = np.matrix([[1, -.5], [-.5, 1]])\n",
        "b = np.matrix([[-10], [3]])\n",
        "lambda_ = 4 # TRY also lambda = 12\n",
        "\n",
        "fig_data_r2 = plot_toy_problem_R2(A, b, lambda_)\n",
        "\n",
        "# dual\n",
        "d_prms = {\"tolerance\": 1e-4,\n",
        "          \"delta\": 1e-1,\n",
        "          \"max_iters\": 1000}\n",
        "x_star, y_star, fps, fds = toy_dual(A, b, lambda_, d_prms, fig_data_r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>\n",
        "\n"
      ],
      "metadata": {
        "id": "WFko4HMC86H2"
      }
    }
  ]
}