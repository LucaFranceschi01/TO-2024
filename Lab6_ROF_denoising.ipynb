{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM_ErGq-k_3c"
      },
      "source": [
        "# Group Members:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**PUT NAMES OF YOUR TEAM MEMBERS HERE**"
      ],
      "metadata": {
        "id": "kabcI8Wj5cKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Name 1\n",
        "*   Name 2\n",
        "*   Name 3"
      ],
      "metadata": {
        "id": "Fnul20Qf5f0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guide"
      ],
      "metadata": {
        "id": "oJoeM0yp_REU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this practice we will implement an image denoising energy, published in 1992 by Rudin, Osher and Fatemi. It is called the ROF denoising model.\n",
        "\n",
        "\\\\\n",
        "\n",
        "For any doubts before and after the practice, you can contact your teacher:\n",
        "\n",
        "Nneka Okolo - nnekamaureen.okolo@upf.edu\n",
        "\n",
        "Pablo Arias - pablo.arias@upf.edu\n",
        "\n",
        "Adriano Pastore - adriano.pastore@upf.edu\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Deadlines**: See\n",
        "[P101](https://calendar.google.com/calendar/embed?src=c_b679939a9db8a1d8cd9f01f62d373d173f76794e4137c40e793a8d2cb11708f8%40group.calendar.google.com&ctz=Europe%2FMadrid/),\n",
        "[P102](https://calendar.google.com/calendar/embed?src=c_5a65338fe8c3ce7909e62bb6b572b1a61ff4ad3543b12f72468e1a16bca41bd0%40group.calendar.google.com&ctz=Europe%2FMadrid),\n",
        "[P201](https://calendar.google.com/calendar/embed?src=c_58aa336a0c5d0a38b13dd4a38071e7d8f9a18f4306ffeef2e48276087c339163%40group.calendar.google.com&ctz=Europe%2FMadrid),\n",
        "[P202](https://calendar.google.com/calendar/embed?src=c_dac1d492e1060f3cee35420a9c2ff0d345e89a002cc8c70fe74bf0b78bf99d37%40group.calendar.google.com&ctz=Europe%2FMadrid),\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Submission instructions**\n",
        "\n",
        "Register your group members [here](https://forms.gle/NLeYqhN6LyPnSPg78) if you haven't already.\n",
        "\n",
        "Complete the code and answer the questions below.\n",
        "\n",
        "Export the notebook with the answers using the menu option File->Download .ipynb.\n",
        "\n",
        "Rename exported notebook with the format **lastnameUid.ipynb** where lastname is the first surname of **Member 1** in the form and Uid is their UPF ID.\n",
        "\n",
        "Submit your solution [here](https://forms.gle/AdYQwDEjAta1QaRY6) by the deadline. **Only one member needs to complete this step**.\n",
        "\n",
        "You will receive an acknowledgement of receipt.\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Grading**:\n",
        "\n",
        "  The evaluation is based on results, conclusions and the commented code together.\n",
        "\n",
        "[comment]: <> (Macros:)\n",
        "$\\newcommand{\\m}{-}\n",
        "\\newcommand{\\ma}[1]{\\boldsymbol{#1}}\n",
        "\\newcommand{\\tras}[1]{#1^{\\mathrm{T}}}\n",
        "\\newcommand{\\herm}[1]{#1^{\\mathrm{H}}}\n",
        "\\newcommand{\\con}[1]{#1^{\\mathrm{*}}}\n",
        "\\newcommand{\\E}{\\mathbb{E}}\n",
        "\\newcommand{\\tech}[1]{\\overline{#1}}\n",
        "\\newcommand{\\nspace}{\\!\\!\\!\\!}\n",
        "\\newcommand{\\nmbr}[1]{\\oldstylenums{#1}}\n",
        "\\newcommand{\\eg}{\\emph{e.g}. } \\newcommand{\\Eg}{\\emph{E.g}. }\n",
        "\\newcommand{\\ie}{\\emph{i.e}. } \\newcommand{\\Ie}{\\emph{I.e}. }\n",
        "\\newcommand{\\cf}{\\emph{c.f}. } \\newcommand{\\Cf}{\\emph{C.f}. }\n",
        "\\newcommand{\\etc}{\\emph{etc}. } \\newcommand{\\vs}{\\emph{vs}. }\n",
        "\\newcommand{\\wrt}{w.r.t\\onedot } \\newcommand{\\dof}{d.o.f. }\n",
        "\\newcommand{\\etal}{\\emph{et al}. }\n",
        "\\newcommand{\\R}{\\mathbb{R}}\n",
        "\\newcommand{\\sign}{\\mathrm{sign}}\n",
        "\\newcommand{\\eps}{\\varepsilon}\n",
        "\\newcommand{\\To}{\\longrightarrow}\n",
        "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
        "\\DeclareMathOperator*{\\argmax}{arg\\,max}$"
      ],
      "metadata": {
        "id": "JCfOu0TE55xS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions for answering the questions.**\n",
        "\n",
        "Questions are indicated in blue. Some questions require answers in the form of text, some others require completing code. See the examples below. *Please do not modify the notebook outside of these cells.*"
      ],
      "metadata": {
        "id": "jzaSqp7hJYC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 42)** Based on what you know at this moment, answer these questions:\n",
        "1. What are your favorite subjects?\n",
        "2. What are your favourite hobbies?\n",
        "</font>"
      ],
      "metadata": {
        "id": "R-IHsJZ0JaKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>\n",
        "\n",
        "1. I only like one subject: \"Optimization Techniques.\"\n",
        "1. I like writing equations $e^{i\\pi} + 1 = 0$"
      ],
      "metadata": {
        "id": "xGxO_cnuJcRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 43)** This is a coding question. There is no <font color='red'>**ANSWER**</font> cell. Instead, you should complete the code cell following the question. Typically, you'll find TODOs in the code indicating the places that you are expected to complete.\n",
        "</font>"
      ],
      "metadata": {
        "id": "LjfQhH4OJeoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = None     # TODO substitute the None by a nice number to print\n",
        "print(\"The number a is {}\".format(a))"
      ],
      "metadata": {
        "id": "P1YokEN8JlSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An energy for edge-preserving image denoising\n",
        "\n",
        "We use the same notation as in the previous assignments. We consider a scalar image $f:\\Omega\\rightarrow \\mathbb R$ defined over the rectangular discrete lattice $\\Omega = \\{1,\\dots,M\\}\\times\\{1,\\dots,N\\}$ ($N$ columns and $M$ rows). Assume $f$ has some noise we want to remove.\n",
        "\n",
        "In Lab 2, we performed image denoising by minimizing an energy similar to the following quadratic energy:\n",
        "\n",
        "\\begin{multline*}\n",
        "\tE_2(u) = \\sum_{i = 1}^M\\sum_{j = 1}^N ((\\nabla_i^+u_{ij})^2+(\\nabla_j^+u_{ij})^2) + \\frac{1}{2 \\lambda} \\sum_{i = 1}^M\\sum_{j = 1}^N (u_{ij} -\n",
        "\tf_{ij})^2,\\\\\n",
        "\t= \\sum_{i = 1}^M\\sum_{j = 1}^N\n",
        "\t|\\nabla^+u_{ij}|^2 +\n",
        "\\frac{1}{2\\lambda}\\sum_{i = 1}^M\\sum_{j = 1}^N (u_{ij} -\n",
        "\tf_{ij})^2.\n",
        "\t\\end{multline*}\n",
        "\n",
        "As we observed, this energy has a problem: it smoothes the edges of the image. The ROF denoising model is a slight modification of this energy:\n",
        "\\begin{multline*}\n",
        "\tE(u) = \\sum_{i = 1}^M\\sum_{j = 1}^N \\sqrt{(\\nabla_i^+u_{ij})^2+(\\nabla_j^+u_{ij})^2} + \\frac{1}{2 \\lambda} \\sum_{i = 1}^M\\sum_{j = 1}^N (u_{ij} -\n",
        "\tf_{ij})^2\\\\\n",
        "\t= \\sum_{i = 1}^M\\sum_{j = 1}^N\n",
        "\t|\\nabla^+u_{ij}| +\n",
        "\\frac{1}{2\\lambda}\\sum_{i = 1}^M\\sum_{j = 1}^N (u_{ij} -\n",
        "\tf_{ij})^2.\n",
        "\t\\end{multline*}\n",
        "\n",
        "We will see, that this slight modification has important consequences.\n",
        "\n",
        "## Removing the non-differentiability with an auxiliary variable\n",
        "\n",
        "The energy $E(u)$ is not differentiable. Indeed, it has as many non-differentiabilities as pixels: one for each term $|\\nabla^+u_{ij}|$. For each one of them we add an auxiliary variable $p_{ij} \\in \\R^2$ and express the energy as a min-max problem:\n",
        "$$\n",
        "\\min E(u) = \\min \\limits_u \\max \\limits_{p \\in C} \\sum_{i = 1}^M\\sum_{j = 1}^N \\nabla ^+ u_{ij} \\cdot p_{ij} + \\frac{1}{2\\lambda} \\sum_{i = 1}^M\\sum_{j = 1}^N (u_{ij} - f_{ij})^2\n",
        "$$\n",
        "Note that we have arranged all the dual variables in a vector-valued image $p \\in \\mathcal{Y}$. The set $C$ is given by\n",
        "$$\n",
        "C= \\{ p : \\Omega \\rightarrow \\R^2 : | p_{ij}| \\leq 1 \\}\n",
        "$$\n",
        "\n",
        "It is the set of all vector valued images which in all pixels $ij$ have a vector $p_{ij}$ of norm smaller or equal than one. Keep in mind that $p_{ij}\\in \\R^2$ and that $|\\cdot|$ is the norm in $\\R^2$.\n",
        "\n",
        "Now we can use the vector representation of images and note that we can express the energy as follows\n",
        "\n",
        "$$\n",
        "\\min E(u) = \\min \\limits_u \\max \\limits_{p \\in C} \\langle \\nabla^+u,p \\rangle_\\mathcal{Y} + \\frac{1}{2 \\lambda} \\| u -f \\|^2_\\mathcal{X}\n",
        "$$\n",
        "\n",
        "This way of writing the energy will facilitate the computation derivatives. Let us define the primal-dual energy\n",
        "$$\n",
        "G(u,p)= \\langle \\nabla^+u,p \\rangle_\\mathcal{Y} + \\frac{1}{2 \\lambda} \\| u-f\\|^2_\\mathcal{X}\n",
        "$$\n",
        "\n",
        "Note that this energy has the exact same form of the energies we studied in Lab 5. The only thing that changed is the form of the feasible set $C$.\n",
        "\n",
        "This means that all that we did before applies to this case: the energy is convex with respect to $u$ and concave with respect to $p$ and the max-min problem is equivalent to the min-max.\n",
        "\n",
        "We will solve the min-max problem using primal-dual and dual schemes exactly like we did before, with $A = \\nabla^+ , A^T = -\\mathrm{div}^- ,$ and $b = f$ . We only need to modify $P_C$ , the projector over $C$. For any vector-valued image $g : \\Omega \\rightarrow \\R^2$ , let $h = P_C(g)$ be its projection, then\n",
        "$$\n",
        "h_{ij} = \\frac{g_{ij}}{\\max \\{ 1, |g_{ij}|\\}} = \\frac{1}{\\max \\{ 1, \\sqrt{g^2_{1,ij}+ g^2_{2,ij}}\\}}(g_{1,ij} , g_{2,ij})\n",
        "$$\n",
        "\n",
        "Observe that $|h_{ij}| \\leq1$ for all $(i, j) \\in \\Omega$ and therefore $h \\in C$."
      ],
      "metadata": {
        "id": "baZGHATBn3BT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Z8EonG8a--"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output, display\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7eJfnnUJFA3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/OptTechCourse_Aux/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXtmB6gwI2wD"
      },
      "outputs": [],
      "source": [
        "# Update your local repo via git pull\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDEuiGyGI7iS"
      },
      "outputs": [],
      "source": [
        "# Create source path\n",
        "source = \"/content/drive/MyDrive/OptTechCourse_Aux/Lab6/\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlxHlIv88a-_"
      },
      "source": [
        "# Read the image\n",
        "images_dir = os.path.abspath(source+\"images\")\n",
        "image_real = np.array(Image.open(os.path.join(images_dir, \"boat.tiff\")))\n",
        "np.random.seed(4)\n",
        "image_noisy = image_real + 20 * np.random.normal(size = image_real.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (20, 12))\n",
        "ax1.imshow(image_real, cmap = \"gray\")\n",
        "ax1.set_title(\"Real image\")\n",
        "ax2.imshow(image_noisy, cmap = \"gray\")\n",
        "ax2.set_title(\"Noisy Image\")"
      ],
      "metadata": {
        "id": "KbzM4JKYeDj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let us define `im_fwd_gradient` and `im_bwd_divergence` functions to implement the forward gradient and backward divergence operations, as we have already studied them in previous labs."
      ],
      "metadata": {
        "id": "evt13_zFnmPr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlJjRFiT8a-_"
      },
      "source": [
        "def im_fwd_gradient(image: np.ndarray):\n",
        "    \"\"\"\n",
        "    Discrete gradient of an image using forward differences, with homogeneous Neuman boundary conditions.\n",
        "\n",
        "    :param u: image (MxN)\n",
        "\n",
        "    :return gradu_j: partial derivative in the j (rows) direction (also x direction)\n",
        "    :return gradu_i: partial derivative in the i (cols) direction (also y direction)\n",
        "    \"\"\"\n",
        "    # Get the size of the image\n",
        "    image_shape = image.shape\n",
        "\n",
        "    # Calculate both gradients\n",
        "    gradu_j = np.append(np.diff(image, axis = 1), np.zeros((image_shape[0], 1)), axis = 1)\n",
        "    gradu_i = np.append(np.diff(image, axis = 0), np.zeros((1, image_shape[1])), axis = 0)\n",
        "    return gradu_i, gradu_j\n",
        "\n",
        "def im_bwd_divergence(gradient_i: np.ndarray,\n",
        "                      gradient_j: np.ndarray):\n",
        "    \"\"\"\n",
        "    Discrete divergence of a vector field using backwards differences.\n",
        "    This is the negative transpose of the im_fwd_gradient\n",
        "\n",
        "    :param gradient_i: component of g in the direction j (rows) (also x direction)\n",
        "    :param gradient_j: component of g in the direction i (cols) (also y direction)\n",
        "\n",
        "    :return divg: backwards divergence of g\n",
        "    \"\"\"\n",
        "    # Backwards j partial derivative of gradient_j\n",
        "    gradient_j[:, gradient_j.shape[1] - 1] = 0\n",
        "    divg = np.diff(np.append(np.zeros((gradient_j.shape[0], 1)), gradient_j, axis = 1), axis = 1)\n",
        "\n",
        "    # Backwards i partial derivative of gradient_i\n",
        "    gradient_i[gradient_i.shape[0] - 1, :] = 0\n",
        "    divg = np.diff(np.append(np.zeros((1, gradient_i.shape[1])), gradient_i, axis = 0), axis = 0) + divg\n",
        "\n",
        "    return divg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Primal-dual problem\n",
        "\n",
        "In a primal-dual scheme we look for a saddle point $(u^*, p^*)$ of $G$. A saddle-point is a minimum in $u$ and a maximum in $p$. To find it we do an iterative scheme, updating $u$ using a gradient descent and $p$ with a gradient ascent. Using the formulas derived in the previous part we have that:\n",
        "$$\n",
        "\\nabla_p G(u,p) = \\nabla ^+ u,\n",
        "$$\n",
        "$$\n",
        "\\nabla_u G(u,p) = -\\mathrm{div}^-p + \\frac{1}{\\lambda}(u-f).\n",
        "$$\n",
        "\n",
        "Given an initialization $u^0,p^0$ , and time step parameters $\\delta$, $\\theta>0$, the primal-dual scheme is as follows:\n",
        "\n",
        "$$u^{k+1}=u^k - \\theta (\\frac{1}{\\lambda}(u^k-f) - \\mathrm{div}^-p^k) $$\n",
        "$$p^{k+1} = P_C(p^k + \\delta \\nabla^+ u^{k+1})$$\n",
        "\n",
        "Note that since $p$ is constrained to the set $C$, we have to use a projected gradient ascent."
      ],
      "metadata": {
        "id": "8F3gHHBcveAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 1)** Complete the function `rof_primal_dual`. Do not use Python loops. Follow the comments provided in the code.\n",
        "</font>"
      ],
      "metadata": {
        "id": "BmPbuRl_sYSv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGtLvaeQ8a_A"
      },
      "source": [
        "def rof_primal_dual(f: np.ndarray,\n",
        "                    lambda_: float,\n",
        "                    pd_prms: dict,\n",
        "                    fig, ax1, ax2):\n",
        "    \"\"\"\n",
        "    rof_primal_dual - minimizes the ROF denoising energy using a primal-dual\n",
        "                      scheme to solve the min-max problem.\n",
        "\n",
        "    :param f      : MxN noisy image\n",
        "    :param lambda : weight between regularization and data attachement term\n",
        "    :param pd_prms: dictionary with parameters of primal dual method:\n",
        "                    delta     : dual gradient ascent step size\n",
        "                    theta     : primal gradient descent step size\n",
        "                    max_iters : maximum number of iterations\n",
        "                    tolerance : tolerance on dual gap for the stopping condition\n",
        "\n",
        "    :return u  : primal value found (MxN)\n",
        "    :return p_i: dual optimum, horizontal component (MxN)\n",
        "    :return p_j: dual optimum, vertical   component (MxN)\n",
        "    :return fps: evolution of the primal function (vector of length total_iters)\n",
        "    :return fds: evolution of the dual   function (vector of length total_iters)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the params\n",
        "    max_iters = pd_prms.get(\"max_iters\")\n",
        "    tolerance = pd_prms.get(\"tolerance\")\n",
        "    delta     = pd_prms.get(\"delta\")\n",
        "    theta     = pd_prms.get(\"theta\")\n",
        "    sz = f.shape # M = sz(1), N = sz(2)\n",
        "\n",
        "    # initialize primal variable\n",
        "    u = f\n",
        "\n",
        "    # initialize dual variable (a vector valued image)\n",
        "    p_j = np.zeros(sz)\n",
        "    p_i = np.zeros(sz)\n",
        "    div_p = im_bwd_divergence(p_i, p_j)\n",
        "\n",
        "    # grad of f, needed later\n",
        "    gf_i, gf_j = im_fwd_gradient(f)\n",
        "\n",
        "    # vectors with function values\n",
        "    fps = []\n",
        "    fds = []\n",
        "\n",
        "    it = 0\n",
        "    dual_gap = np.inf\n",
        "    while (dual_gap > tolerance) and (it < max_iters):\n",
        "\n",
        "        # Update the iteration counter\n",
        "        it += 1\n",
        "\n",
        "        # TODO: update primal variable with a gradient descent step\n",
        "        u = None\n",
        "        gu_i, gu_j = None, None\n",
        "\n",
        "        # TODO: gradient ascent on dual variable\n",
        "        p_i = None\n",
        "        p_j = None\n",
        "\n",
        "        # TODO: project over the feasible set. Do not use Python loops\n",
        "        p_i = None\n",
        "        p_j = None\n",
        "\n",
        "        # TODO: update divergence of dual variable p\n",
        "        div_p = None\n",
        "\n",
        "        # TODO primal energy\n",
        "        PE = None\n",
        "        PE = None\n",
        "\n",
        "        # TODO: dual energy\n",
        "        DE = (gf_i * p_i).sum() + (gf_j * p_j).sum() - \\\n",
        "             lambda_/2 * (div_p ** 2).sum()\n",
        "\n",
        "        # we normalize the energies between the number of pixels\n",
        "        PE = PE / np.prod(sz)\n",
        "        DE = DE / np.prod(sz)\n",
        "\n",
        "        # dual gap\n",
        "        dual_gap = PE - DE\n",
        "\n",
        "        fps.append(PE)\n",
        "        fds.append(DE)\n",
        "\n",
        "        # Plot\n",
        "        if it % 10 == 0:\n",
        "            # display primal and dual variable\n",
        "            ax1.imshow(u, cmap = \"gray\")\n",
        "            ax2.imshow(np.concatenate((p_i, p_j), axis = 1), cmap = \"gray\")\n",
        "            clear_output(wait=True)\n",
        "            display(fig)\n",
        "\n",
        "            # display information - dual gap\n",
        "            print(\"[it {0} of {1}] DG = {2} - {3} = {4}\".format(it, max_iters, PE, DE, dual_gap))\n",
        "\n",
        "    return u, p_i, p_j, fps, fds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3Et5phL8a_B"
      },
      "source": [
        "### Run the primal-dual algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5U1wkId8a_C"
      },
      "source": [
        "# Define the parameters\n",
        "lambda_ = 30\n",
        "pd_prms = {\"max_iters\": 500,\n",
        "            \"tolerance\": 1e-4,\n",
        "            \"delta\": 1/2,\n",
        "            \"theta\": 1/2\n",
        "           }\n",
        "\n",
        "# Build up the plot\n",
        "fig, (ax1, ax2) = plt.subplots(nrows = 2, ncols = 1, figsize = (14, 8))\n",
        "ax1.set_title(\"Primal\")\n",
        "ax2.set_title(\"Dual\")\n",
        "\n",
        "# Run the primal dual\n",
        "_, _, _, fps, fds = rof_primal_dual(image_noisy, lambda_, pd_prms, fig, ax1, ax2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## The dual algorithm\n",
        "\n",
        "The objective again is to solve the max-min problem:\n",
        "\n",
        "$$\\max \\limits_{p\\in C} \\min\\limits_{u} G(u,p) = \\langle \\nabla^+ u,p \\rangle_{\\mathcal{Y}} + \\frac{1}{2 \\lambda} \\|u-f\\|^2_\\mathcal{X}$$\n",
        "\n",
        "The interior minimization problem with respect to u is easy to solve: it is a quadratic unconstrained problem. Thus, we can compute the minimum $u^*(p)$ as a function of $p$. From the previous part we get that\n",
        "\n",
        "$$u^*(p) = f + \\lambda \\mathrm{div}^- p$$\n",
        "\n",
        "Now we compute the dual energy as $E_D(p) = \\min_u G(u, p) = G(u^*(p), p)$. The dual scheme is a projected gradient ascent on the dual energy $E_D$. Again, from the previous part we have that\n",
        "\n",
        "$$E_D(p) = \\langle \\nabla^+ f,p\\rangle_\\mathcal{Y} - \\frac{\\lambda}{2} \\|\\mathrm{div}^-p\\|^2_\\mathcal{X}$$\n",
        "\n",
        "Taking the gradient we obtain:\n",
        "\n",
        "$$\\nabla E_D (p) = \\nabla ^+f+ \\lambda \\nabla^+ \\mathrm{div}^- p = \\nabla ^+ (f+\\lambda \\mathrm{div}^- p) = \\nabla ^+ u^* (p).$$\n",
        "\n",
        "Putting all together, we have the following projected gradient ascent scheme to\n",
        "maximize the dual energy, where $\\delta$ is the step of the gradient ascent:\n",
        "\n",
        "$$p^{k+1} = P_C(p^k + \\delta \\nabla^+(f+\\lambda \\mathrm{div}^-(p^k))$$\n",
        "\n",
        "The projection operator is the same as before. Note that the dual scheme does not need the computation of the primal variable. **It only works on the dual domain.** Once the dual maximization finishes, we obtain $p^*$, and then we can compute the primal optimum as $u^*(p^*)$. In practice we will use the following scheme, which is exactly equivalent to the previous one, with the only difference that we identify the primal variable explicitly:\n",
        "\n",
        "$$\n",
        "\\left\\{\n",
        "  \\begin{array}{l}\n",
        "  u^*(p^k) = f + \\lambda \\mathrm{div}^-p^k  \\\\\n",
        "p^{k+1} = P_C(p^k + \\delta \\nabla^+u^*(p^k))\n",
        "  \\end{array}\n",
        "\\right.$$\n",
        "\n",
        "In this way we can compute the primal energy (and thus the dual gap) and visualize the evolution of the image during the iterations."
      ],
      "metadata": {
        "id": "hLuHEaStvzKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 2)** Complete the function `rof_dual`. Follow the comments provided in the code. Do not use Python loops.\n",
        "</font>"
      ],
      "metadata": {
        "id": "vNTPELiMsa0P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO7772IE8a_D"
      },
      "source": [
        "def rof_dual(f: np.ndarray,\n",
        "             lambda_: float,\n",
        "             pd_prms: dict,\n",
        "             fig, ax1, ax2):\n",
        "    \"\"\"\n",
        "    rof_dual - minimizes the ROF denoising energy using Chambolle's dual\n",
        "               projected gradient ascent.\n",
        "\n",
        "    :param f     : MxN noisy image\n",
        "    :param lambda: weight between regularization and data attachement term\n",
        "    :param d_prms: dictionary with parameters of dual method:\n",
        "                   delta     : gradient ascent step size\n",
        "                   max_iters : maximum number of iterations\n",
        "                   tolerance : tolerance on dual gap for the stopping condition\n",
        "\n",
        "    :return u   : primal value found (MxN)\n",
        "    :return xi_j: dual optimum, horizontal component (MxN)\n",
        "    :return xi_i: dual optimum, vertical   component (MxN)\n",
        "    :return fps : evolution of the primal function (vector of length total_iters)\n",
        "    :return fds : evolution of the dual   function (vector of length total_iters)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the params\n",
        "    max_iters = pd_prms.get(\"max_iters\")\n",
        "    tolerance = pd_prms.get(\"tolerance\")\n",
        "    delta     = pd_prms.get(\"delta\")\n",
        "    sz = f.shape\n",
        "\n",
        "    # initialize dual variable (a vector valued image)\n",
        "    p_j = np.zeros(sz)\n",
        "    p_i = np.zeros(sz)\n",
        "    div_p = im_bwd_divergence(p_i, p_j)\n",
        "\n",
        "    # grad of f, needed later\n",
        "    gf_i, gf_j = im_fwd_gradient(f)\n",
        "\n",
        "    # vectors with function values\n",
        "    fps = []\n",
        "    fds = []\n",
        "\n",
        "    it = 0\n",
        "    dual_gap = np.inf\n",
        "    while (dual_gap > tolerance) and (it < max_iters):\n",
        "\n",
        "        # Update the iteration counter\n",
        "        it += 1\n",
        "\n",
        "        # TODO: update primal variable and its gradient - this is u^*(xi) for current xi\n",
        "        u_star = None\n",
        "        gu_star_i, gu_star_j = None\n",
        "\n",
        "        # TODO: update dual variable - gradient ascent\n",
        "        p_i = None\n",
        "        p_j = None\n",
        "\n",
        "        # TODO: project over the feasible set\n",
        "        p_i = None\n",
        "        p_j = None\n",
        "\n",
        "        # TODO: update divergence of dual\n",
        "        div_p = None\n",
        "\n",
        "        # TODO: primal energy\n",
        "        PE = None\n",
        "        PE = None\n",
        "\n",
        "        # TODO: dual energy\n",
        "        DE = None\n",
        "\n",
        "        # we normalize the energies between the number of pixels\n",
        "        PE = PE / np.prod(sz)\n",
        "        DE = DE / np.prod(sz)\n",
        "\n",
        "        # dual gap\n",
        "        dual_gap = PE - DE\n",
        "\n",
        "        fps.append(PE)\n",
        "        fds.append(DE)\n",
        "\n",
        "        # Plot\n",
        "        if it % 10 == 0:\n",
        "            # display primal and dual variable\n",
        "            ax1.imshow(u_star, cmap = \"gray\")\n",
        "            ax2.imshow(np.concatenate((p_i, p_j), axis = 1), cmap = \"gray\")\n",
        "            clear_output(wait=True)\n",
        "            display(fig)\n",
        "\n",
        "            # display information - dual gap\n",
        "            print(\"[it {0} of {1}] DG = {2} - {3} = {4}\".format(it, max_iters, PE, DE, dual_gap))\n",
        "\n",
        "    return u_star, p_i, p_j, fps, fds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j665J8TV8a_E"
      },
      "source": [
        "### Run the dual algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt6sVhcp8a_E"
      },
      "source": [
        "# Define the parameters\n",
        "lambda_ = 30\n",
        "pd_prms = {\"max_iters\": 500,\n",
        "            \"tolerance\": 1e-4,\n",
        "            \"delta\": 1/4.5 / lambda_\n",
        "           }\n",
        "\n",
        "# Build up the plot\n",
        "fig, (ax1, ax2) = plt.subplots(nrows = 2, ncols = 1, figsize = (14, 8))\n",
        "ax1.set_title(\"Primal\")\n",
        "ax2.set_title(\"Dual\")\n",
        "\n",
        "# Run the primal dual\n",
        "_, _, _, fps, fds = rof_dual(image_noisy, lambda_, pd_prms, fig, ax1, ax2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Try different values of $\\lambda$. Answer (briefly) the following questions.\n",
        "</font>"
      ],
      "metadata": {
        "id": "omEmVPXfwA5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 3.1)** What is the effect of $\\lambda$ on the results?\n",
        "</font>"
      ],
      "metadata": {
        "id": "PaDvvxv-wbrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>"
      ],
      "metadata": {
        "id": "G6b-4sLlwA5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 3.2)** Compare the quality of the results obtained with those obtained in Lab 2. Are the edges of the image well preserved?\n",
        "</font>"
      ],
      "metadata": {
        "id": "uzJklMJYwmHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>"
      ],
      "metadata": {
        "id": "kJP54WY5w9IZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**(QUESTION 3.3)** Plot in a same graph the evolution of the dual gap with the iterations for both methods (the dual and the primal dual). Use a logarithmic axis for the dual gap (you can use the function `semilogy` instead of `plot`). Which method converges faster? What happens when you change step size $\\delta$?\n",
        "</font>"
      ],
      "metadata": {
        "id": "JA0AFQzDwmWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## INSERT YOUR CODE HERE"
      ],
      "metadata": {
        "id": "KgN5Pm5ExNji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**ANSWER**</font>"
      ],
      "metadata": {
        "id": "rzCjth4Lw9dA"
      }
    }
  ]
}